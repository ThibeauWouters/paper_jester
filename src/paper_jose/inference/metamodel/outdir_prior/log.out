Sat Dec 28 11:23:08 CET 2024
NVIDIA A100-SXM4-40GB
2024-12-28 11:23:10.296398: W external/xla/xla/service/gpu/nvptx_compiler.cc:836] The NVIDIA driver's CUDA version is 12.5 which is older than the PTX compiler version (12.6.85). Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.
Warning: weights not properly specified, assuming constant weights instead.
GPU found?
[CudaDevice(id=0)]
Using the broad EOS prior
WARNING: This is a metamodel run with no CSE parameters!
Fixed params loaded inside the MicroToMacroTransform:
    E_sat: -16.0
    nbreak: 0.153406
    cs2_CSE_0: 0.5
    cs2_CSE_1: 0.7
    cs2_CSE_2: 0.5
    cs2_CSE_3: 0.4
    cs2_CSE_4: 0.8
    cs2_CSE_5: 0.6
    cs2_CSE_6: 0.9
    cs2_CSE_7: 0.8
    cs2_CSE_8: 0.9
WARNING: This is a metamodel run with no CSE parameters!
Fixed params loaded inside the MicroToMacroTransform:
    E_sat: -16.0
    nbreak: 0.153406
    cs2_CSE_0: 0.5
    cs2_CSE_1: 0.7
    cs2_CSE_2: 0.5
    cs2_CSE_3: 0.4
    cs2_CSE_4: 0.8
    cs2_CSE_5: 0.6
    cs2_CSE_6: 0.9
    cs2_CSE_7: 0.8
    cs2_CSE_8: 0.9
Using the zero likelihood:
We are going to give these kwargs to Jim:
{'n_loop_training': 20, 'n_loop_production': 20, 'n_chains': 1000, 'n_local_steps': 2, 'n_global_steps': 100, 'n_epochs': 20, 'train_thinning': 1, 'output_thinning': 5}
We are going to sample the following parameters:
['E_sym', 'L_sym', 'K_sym', 'Q_sym', 'Z_sym', 'K_sat', 'Q_sat', 'Z_sat']
No sample transforms provided. Using prior parameters as sampling parameters
['n_dim', 'n_chains', 'n_local_steps', 'n_global_steps', 'n_loop', 'output_thinning', 'verbose']
log_prob
[0. 0. 0.]
Sampling seed is set to: 11
Global Tuning:   0%|          | 0/20 [00:00<?, ?it/s]Global Tuning:   5%|▌         | 1/20 [00:29<09:11, 29.03s/it]Global Tuning:  10%|█         | 2/20 [00:29<03:43, 12.43s/it]Global Tuning:  15%|█▌        | 3/20 [00:30<02:01,  7.12s/it]Global Tuning:  20%|██        | 4/20 [00:31<01:14,  4.63s/it]Global Tuning:  25%|██▌       | 5/20 [00:32<00:48,  3.25s/it]Global Tuning:  30%|███       | 6/20 [00:33<00:33,  2.42s/it]Global Tuning:  35%|███▌      | 7/20 [00:33<00:24,  1.89s/it]Global Tuning:  40%|████      | 8/20 [00:34<00:18,  1.54s/it]Global Tuning:  45%|████▌     | 9/20 [00:35<00:14,  1.31s/it]Global Tuning:  50%|█████     | 10/20 [00:36<00:11,  1.15s/it]Global Tuning:  55%|█████▌    | 11/20 [00:37<00:09,  1.05s/it]Global Tuning:  60%|██████    | 12/20 [00:37<00:07,  1.03it/s]Global Tuning:  65%|██████▌   | 13/20 [00:38<00:06,  1.08it/s]Global Tuning:  70%|███████   | 14/20 [00:39<00:05,  1.13it/s]Global Tuning:  75%|███████▌  | 15/20 [00:40<00:04,  1.16it/s]Global Tuning:  80%|████████  | 16/20 [00:41<00:03,  1.19it/s]Global Tuning:  85%|████████▌ | 17/20 [00:41<00:02,  1.20it/s]Global Tuning:  90%|█████████ | 18/20 [00:42<00:01,  1.22it/s]Global Tuning:  95%|█████████▌| 19/20 [00:43<00:00,  1.23it/s]Global Tuning: 100%|██████████| 20/20 [00:44<00:00,  1.23it/s]Global Tuning: 100%|██████████| 20/20 [00:44<00:00,  2.21s/it]
Compiling MALA body
Global Sampling:   0%|          | 0/20 [00:00<?, ?it/s]Global Sampling:   5%|▌         | 1/20 [00:00<00:03,  6.01it/s]Global Sampling:  10%|█         | 2/20 [00:00<00:02,  6.42it/s]Global Sampling:  15%|█▌        | 3/20 [00:00<00:02,  6.57it/s]Global Sampling:  20%|██        | 4/20 [00:00<00:02,  6.63it/s]Global Sampling:  25%|██▌       | 5/20 [00:00<00:02,  6.68it/s]Global Sampling:  30%|███       | 6/20 [00:00<00:02,  6.71it/s]Global Sampling:  35%|███▌      | 7/20 [00:01<00:01,  6.72it/s]Global Sampling:  40%|████      | 8/20 [00:01<00:01,  6.72it/s]Global Sampling:  45%|████▌     | 9/20 [00:01<00:01,  6.74it/s]Global Sampling:  50%|█████     | 10/20 [00:01<00:01,  6.74it/s]Global Sampling:  55%|█████▌    | 11/20 [00:01<00:01,  6.75it/s]Global Sampling:  60%|██████    | 12/20 [00:01<00:01,  6.76it/s]Global Sampling:  65%|██████▌   | 13/20 [00:01<00:01,  6.76it/s]Global Sampling:  70%|███████   | 14/20 [00:02<00:00,  6.76it/s]Global Sampling:  75%|███████▌  | 15/20 [00:02<00:00,  6.77it/s]Global Sampling:  80%|████████  | 16/20 [00:02<00:00,  6.77it/s]Global Sampling:  85%|████████▌ | 17/20 [00:02<00:00,  6.77it/s]Global Sampling:  90%|█████████ | 18/20 [00:02<00:00,  6.78it/s]Global Sampling:  95%|█████████▌| 19/20 [00:02<00:00,  6.78it/s]Global Sampling: 100%|██████████| 20/20 [00:02<00:00,  6.78it/s]Global Sampling: 100%|██████████| 20/20 [00:02<00:00,  6.72it/s]
Training summary
==========
E_sym: 36.487 +/- 4.924
L_sym: 105.110 +/- 55.328
K_sym: -99.933 +/- 115.881
Q_sym: -1.712 +/- 462.794
Z_sym: -493.011 +/- 1160.748
K_sat: 224.847 +/- 43.280
Q_sat: 293.266 +/- 464.924
Z_sat: -491.192 +/- 1152.820
Log probability: -50.426 +/- 0.000
Local acceptance: 1.000 +/- 0.007
Global acceptance: 0.544 +/- 0.498
Max loss: 17.237, Min loss: 10.056
Production summary
==========
E_sym: 36.714 +/- 4.939
L_sym: 103.613 +/- 54.979
K_sym: -90.537 +/- 118.795
Q_sym: 2.963 +/- 458.385
Z_sym: -454.243 +/- 1154.496
K_sat: 222.557 +/- 43.443
Q_sat: 286.119 +/- 457.018
Z_sat: -521.721 +/- 1171.068
Log probability: -50.426 +/- 0.000
Local acceptance: 1.000 +/- 0.020
Global acceptance: 0.541 +/- 0.498
S has been successful, now we will do some postprocessing. Sampling time: roughly 1 mins
Saving the final results
Number of samples generated in training: 420000
Number of samples generated in production: 420000
Number of samples generated: 840000
Time taken for TOV map: 72.82094144821167 s
DONE entire script
DONE

JOB STATISTICS
==============
Job ID: 9176758
Cluster: snellius
User/Group: twouters2/twouters2
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:03:19
CPU Efficiency: 5.76% of 00:57:36 core-walltime
Job Wall-clock time: 00:03:12
Memory Utilized: 1.73 GB
Memory Efficiency: 17.33% of 10.00 GB
